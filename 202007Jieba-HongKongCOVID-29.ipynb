{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in ./venv/lib/python3.7/site-packages (20.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "from optparse import OptionParser\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pyecharts.charts import WordCloud\n",
    "!pip install --upgrade pip\n",
    "import seaborn as sns\n",
    "import wordcloud\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.font_manager import _rebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paddle enabled successfully......\n"
     ]
    }
   ],
   "source": [
    "jieba.enable_paddle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/1j/d3xd3shn42x71_yhgx8757r80000gn/T/jieba.cache\n",
      "Loading model cost 0.757 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4146\n",
      "4146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"520\"\n",
       "            src=\"detail_zh-wordcloud.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fef2d597b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "#set stopwords\n",
    "def stopwordslist(filepath):   \n",
    "    stopwords = [line.strip() for line in open(filepath, 'r').readlines()]  \n",
    "    return stopwords #return a list\n",
    "\n",
    "stopwords = stopwordslist('/Users/zhaoxiaozhao/Downloads/stopwords.txt')\n",
    "stopwords = set(stopwords)\n",
    "\n",
    "# print(stopwords)\n",
    "def remove_stopwords(words): #remove stopwords\n",
    "    processed_word_list = []\n",
    "    for word in words:\n",
    "        word = word.lower() # in case they are not all lower cased\n",
    "        if word not in stopwords:\n",
    "            processed_word_list.append(word)\n",
    "    return processed_word_list\n",
    "\n",
    "def word_list(filename):\n",
    "    #Input your own file location(text location)\n",
    "    with open('/Users/zhaoxiaozhao/Downloads/'+ filename, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "        test_ls = jieba.lcut(data,cut_all=False)\n",
    "        test_ls = remove_stopwords(test_ls)\n",
    "    return test_ls\n",
    "\n",
    "\n",
    "def cnt_words_except_sin(filename):\n",
    "    #Input your own file location(where to store)\n",
    "    with open('/Users/zhaoxiaozhao/Downloads/'+ filename, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "        #使用 jieba.lcut\n",
    "        test_ls_txt = jieba.lcut(data,cut_all=False)\n",
    "        test_ls_txt = remove_stopwords(test_ls_txt)   \n",
    "        dict_words_frequency={}\n",
    "        \n",
    "    for n in test_ls_txt:\n",
    "        if len(n) != 1:\n",
    "            dict_words_frequency[n]=test_ls_txt.count(n)\n",
    "        \n",
    "    cnt = len(dict_words_frequency) #count all words\n",
    "    print(cnt)\n",
    "    #sort the dictionary\n",
    "    sorted_x = sorted(dict_words_frequency.items(), key=lambda kv: kv[1])\n",
    "    dict_words_frequency = collections.OrderedDict(sorted_x)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(dict_words_frequency, orient='index', columns=['count'])\n",
    "    df = df.sort_values(by = ['count'], ascending=True)\n",
    "    # new column for 词频（百分比）\n",
    "    df['q'] = df['count'] / cnt\n",
    "\n",
    "    #return DataFrame(type)\n",
    "    return df\n",
    "\n",
    "# Return 分词 + 词性标注\n",
    "def cnt_words_flag(filename):\n",
    "    #Input your own file location(where to store)\n",
    "    with open('/Users/zhaoxiaozhao/Downloads/'+ filename, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "        #使用 pseg.lcut\n",
    "        test_ls = pseg.lcut(data,use_paddle=True)  \n",
    "        dict_words_flags = {}\n",
    "\n",
    "    for i in test_ls:\n",
    "        dict_words_flags[i.word] = i.flag\n",
    "\n",
    "    #return DataFrame(type)\n",
    "    df = pd.DataFrame.from_dict(dict_words_flags, orient='index', columns=['flag'])\n",
    "    \n",
    "    #Input your file name\n",
    "    to_csv(df,'hhh.csv')\n",
    "    return df\n",
    "\n",
    "# sort the df considering 词频（百分比）\n",
    "def sort_q(df):\n",
    "    df = df.sort_values(df.columns[1], ascending=False)\n",
    "    return df\n",
    "\n",
    "# return 2-pair array list for 词云\n",
    "def ls_cnt_words(filename):\n",
    "    with open('/Users/zhaoxiaozhao/Downloads/'+ filename, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "        test_ls = jieba.lcut(data,cut_all=False)\n",
    "        test_ls = remove_stopwords(test_ls)\n",
    "        dict_words_frequency={}\n",
    "    for n in test_ls:\n",
    "        dict_words_frequency[n]=test_ls.count(n)\n",
    "    sorted_x = sorted(dict_words_frequency.items(), key=lambda kv: kv[1])\n",
    "    dict_words_frequency = collections.OrderedDict(sorted_x)\n",
    "    words = list(dict_words_frequency.keys())\n",
    "    value = list(dict_words_frequency.values())   \n",
    "    \n",
    "    new_ls = []\n",
    "    for i in range(len(words)):\n",
    "        new_ls.append((words[i],value[i])) \n",
    "    x = pd.Series(dict_words_frequency)\n",
    "    x = x.sort_values(ascending=False)\n",
    "    print(x.describe())\n",
    "    return new_ls\n",
    "\n",
    "def ls_q_words(df):\n",
    "#     for col in df.columns:\n",
    "    df = df[df.columns]\n",
    "    words = df.index.tolist()\n",
    "    value = df[df.columns[1]].tolist()\n",
    "    \n",
    "    new_ls = []\n",
    "    for i in range(len(words)):\n",
    "        new_ls.append((words[i],value[i]))\n",
    "    \n",
    "    return new_ls\n",
    "\n",
    "\n",
    "def word_count(processed_word_list):\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    word_count = pd.Series(processed_word_list).value_counts().sort_values(ascending=False)[0:15]  \n",
    "    fig = plt.figure(figsize=(16,8))  \n",
    "    x = word_count.index.tolist()  \n",
    "    y = word_count.values.tolist()  \n",
    "    sns.barplot(x, y, palette=\"BuPu_r\")  \n",
    "    plt.title('word frequency top 15')  \n",
    "    plt.ylabel('count')  \n",
    "    sns.despine(bottom=True)  \n",
    "    #plt.savefig('./word_count_bar.png',dpi=400)  \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def to_csv(x,filename):\n",
    "    \n",
    "    Frame=pd.DataFrame(x,columns = ['cnt'])\n",
    "    x.to_csv('/Users/zhaoxiaozhao/Downloads/'+filename, encoding='utf-8')\n",
    "\n",
    "    \n",
    "_rebuild()\n",
    "\n",
    "\n",
    "to_csv(cnt_words_except_sin('detail_zh.txt'),'detail_zh.csv')\n",
    "\n",
    "test_ls = ls_q_words(cnt_words_except_sin('detail_zh.txt'))\n",
    "cnt_words_flag('detail_zh.txt')\n",
    "\n",
    "from PIL import Image\n",
    "import wordcloud\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "wordcloud = WordCloud()\n",
    "wordcloud.add(\"\", test_ls, word_size_range=[20, 100])\n",
    "wordcloud.render('detail_zh-wordcloud.html')\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame('detail_zh-wordcloud.html', width=700, height=520)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
